{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32fb1a2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (Temp/ipykernel_9676/1432368470.py, line 66)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/1432368470.py\"\u001b[1;36m, line \u001b[1;32m66\u001b[0m\n\u001b[1;33m    print('\\nRMSE on test dataset : ', rmse_test)'''\u001b[0m\n\u001b[1;37m                                                    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for the Linear Regression\n",
    "Created by- ANALYTICS VIDHYA\n",
    "'''\n",
    "\n",
    "'''# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train.csv')\n",
    "test_data = pd.read_csv('test.csv')\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "# shape of the dataset\n",
    "print('\\nShape of training data :',train_data.shape)\n",
    "print('\\nShape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Item_Outlet_Sales\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Item_Outlet_Sales'],axis=1)\n",
    "train_y = train_data['Item_Outlet_Sales']\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "test_x = test_data.drop(columns=['Item_Outlet_Sales'],axis=1)\n",
    "test_y = test_data['Item_Outlet_Sales']'''\n",
    "\n",
    "'''\n",
    "Create the object of the Linear Regression model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : fit_intercept and normalize\n",
    "Documentation of sklearn LinearRegression: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "\n",
    " '''\n",
    "model = LinearRegression()\n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# coefficeints of the trained model\n",
    "print('\\nCoefficient of model :', model.coef_)\n",
    "\n",
    "# intercept of the model\n",
    "print('\\nIntercept of model',model.intercept_)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('\\nItem_Outlet_Sales on training data',predict_train) \n",
    "\n",
    "# Root Mean Squared Error on training dataset\n",
    "rmse_train = mean_squared_error(train_y,predict_train)**(0.5)\n",
    "print('\\nRMSE on train dataset : ', rmse_train)\n",
    "\n",
    "# predict the target on the testing dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('\\nItem_Outlet_Sales on test data',predict_test) \n",
    "\n",
    "# Root Mean Squared Error on testing dataset\n",
    "rmse_test = mean_squared_error(test_y,predict_test)**(0.5)\n",
    "print('\\nRMSE on test dataset : ', rmse_test)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5de24bc7",
   "metadata": {},
   "source": [
    "# Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aaf9a3c1",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9676/1660974967.py, line 34)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/1660974967.py\"\u001b[1;36m, line \u001b[1;32m34\u001b[0m\n\u001b[1;33m    Create the object of the Logistic Regression model\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for Logistic Regression\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "\n",
    "# importing required libraries\n",
    "'''import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "\n",
    "print(train_data.head())\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n",
    "'''\n",
    "Create the object of the Logistic Regression model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : fit_intercept and penalty\n",
    "Documentation of sklearn LogisticRegression: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    " '''\n",
    "model = LogisticRegression()\n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# coefficeints of the trained model\n",
    "print('Coefficient of model :', model.coef_)\n",
    "\n",
    "# intercept of the model\n",
    "print('Intercept of model',model.intercept_)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('Target on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('accuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('Target on test data',predict_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(test_y,predict_test)\n",
    "print('accuracy_score on test dataset : ', accuracy_test)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc080902",
   "metadata": {},
   "source": [
    "# TO overcome overfitting , underfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31ecf5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "LINEAR, RIDGE AND LASSO REGRESSION\n",
    "'''\n",
    "# importing requuired libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import Series, DataFrame\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso, Ridge\n",
    "\n",
    "# read test and train file\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "print('\\n\\n---------DATA---------------\\n\\n')\n",
    "print(train.head())\n",
    "\n",
    "#splitting into training and test\n",
    "## try building model with the different features and compare the result.\n",
    "X = train.loc[:,['Outlet_Establishment_Year','Item_MRP']]\n",
    "x_train, x_cv, y_train, y_cv = train_test_split(X,train.Item_Outlet_Sales,random_state=5)\n",
    "\n",
    "print('--------Trainig Linear Regression Model---------------')\n",
    "lreg = LinearRegression()\n",
    "#training the model\n",
    "lreg.fit(x_train,y_train)\n",
    "\n",
    "#predicting on cv\n",
    "pred = lreg.predict(x_cv)\n",
    "\n",
    "#calculating mse\n",
    "mse = np.mean((pred - y_cv)**2)\n",
    "print('\\nMean Sqaured Error = ',mse )\n",
    "\n",
    "#Let us take a look at the coefficients of this linear regression model.\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "\n",
    "coeff['Coefficient Estimate'] = Series(lreg.coef_)\n",
    "\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(lreg.score(x_cv,y_cv))\n",
    "\n",
    "print('\\n\\n---------Training Ridge Regression Model----------------')\n",
    "\n",
    "ridge = Ridge()\n",
    "ridge.fit(x_train,y_train)\n",
    "pred1 = ridge.predict(x_cv)\n",
    "mse_1 = np.mean((pred1-y_cv)**2)\n",
    "\n",
    "print('\\n\\nMean Squared Error = ',mse_1)\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "coeff['Coefficient Estimate'] = Series(ridge.coef_)\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(ridge.score(x_cv,y_cv))\n",
    "\n",
    "\n",
    "print('\\n\\n---------Training Lasso Regression Model----------------')\n",
    "\n",
    "lasso = Lasso()\n",
    "lasso.fit(x_train,y_train)\n",
    "pred2 = lasso.predict(x_cv)\n",
    "mse_2 = np.mean((pred2-y_cv)**2)\n",
    "\n",
    "print('\\n\\nMean Squared Error = ',mse_2)\n",
    "\n",
    "# calculating coefficients\n",
    "coeff = DataFrame(x_train.columns)\n",
    "coeff['Coefficient Estimate'] = Series(lasso.coef_)\n",
    "print(coeff)\n",
    "\n",
    "print('\\n\\nModel performance on Test data = ')\n",
    "print(lasso.score(x_cv,y_cv))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7bd30d",
   "metadata": {},
   "source": [
    "# Decission Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8769e530",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9676/1637650799.py, line 31)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/1637650799.py\"\u001b[1;36m, line \u001b[1;32m31\u001b[0m\n\u001b[1;33m    Create the object of the Decision Tree model\u001b[0m\n\u001b[1;37m           ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for Decision Tree\n",
    "Created by - Analytics Vidhya\n",
    "'''\n",
    "\n",
    "# importing required libraries\n",
    "'''import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n",
    "'''\n",
    "Create the object of the Decision Tree model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : max_depth and max_features\n",
    "Documentation of sklearn DecisionTreeClassifier: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    " '''\n",
    "model = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# depth of the decision tree\n",
    "print('Depth of the Decision Tree :', model.get_depth())\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('Target on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('accuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('Target on test data',predict_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(test_y,predict_test)\n",
    "print('accuracy_score on test dataset : ', accuracy_test)'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2453f1d",
   "metadata": {},
   "source": [
    "# SVM(super vector machine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "78a1bac9",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (Temp/ipykernel_9676/611446662.py, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/611446662.py\"\u001b[1;36m, line \u001b[1;32m57\u001b[0m\n\u001b[1;33m    print('accuracy_score on test dataset : ', accuracy_test)'''\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for Support Vector Machines\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n",
    "'''\n",
    "Create the object of the Support Vector Classifier model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : kernal and degree\n",
    "Documentation of sklearn Support Vector Classifier: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVC.html\n",
    "\n",
    " '''\n",
    "model = SVC()\n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('Target on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('accuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('Target on test data',predict_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(test_y,predict_test)\n",
    "print('accuracy_score on test dataset : ', accuracy_test)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bc468d",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3414163d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "EOF while scanning triple-quoted string literal (Temp/ipykernel_9676/4045877966.py, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/4045877966.py\"\u001b[1;36m, line \u001b[1;32m58\u001b[0m\n\u001b[1;33m    print('accuracy_score on test dataset : ', accuracy_test)'''\u001b[0m\n\u001b[1;37m                                                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m EOF while scanning triple-quoted string literal\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for Naive Bayes\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n",
    "'''\n",
    "Create the object of the Naive Bayes model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : var_smoothing\n",
    "Documentation of sklearn GaussianNB: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html\n",
    "\n",
    " '''\n",
    "model = GaussianNB()\n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('Target on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('accuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('Target on test data',predict_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(test_y,predict_test)\n",
    "print('accuracy_score on test dataset : ', accuracy_test)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c078dd",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56f6fb50",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9676/3384192399.py, line 60)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/3384192399.py\"\u001b[1;36m, line \u001b[1;32m60\u001b[0m\n\u001b[1;33m    print('accuracy_score on test dataset : ', accuracy_test)''\u001b[0m\n\u001b[1;37m                                                             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for the K-Nearest Neighbors\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n",
    "'''\n",
    "Create the object of the K-Nearest Neighbor model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : n_neighbors, leaf_size\n",
    "Documentation of sklearn K-Neighbors Classifier: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "\n",
    " '''\n",
    "model = KNeighborsClassifier()  \n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# Number of Neighbors used to predict the target\n",
    "print('\\nThe number of neighbors used to predict the target : ',model.n_neighbors)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('\\nTarget on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('accuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('Target on test data',predict_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(test_y,predict_test)\n",
    "print('accuracy_score on test dataset : ', accuracy_test)''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc4eae36",
   "metadata": {},
   "source": [
    "# '''\n",
    "The following code is for the Random Forest\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# view the top 3 rows of the dataset\n",
    "print(train_data.head(3))\n",
    "\n",
    "# shape of the dataset\n",
    "print('\\nShape of training data :',train_data.shape)\n",
    "print('\\nShape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n",
    "'''\n",
    "\n",
    "Create the object of the Random Forest model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : n_estimators and max_depth\n",
    "Documentation of sklearn RandomForestClassifier: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "'''\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# number of trees used\n",
    "print('Number of Trees used : ', model.n_estimators)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('\\nTarget on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('\\nTarget on test data',predict_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(test_y,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e0bff82",
   "metadata": {},
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "384838a5",
   "metadata": {},
   "source": [
    "# GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1044cdc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9676/2023575225.py, line 57)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/2023575225.py\"\u001b[1;36m, line \u001b[1;32m57\u001b[0m\n\u001b[1;33m    print('\\naccuracy_score on test dataset : ', accuracy_test)''\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for Gradient Boosting\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n",
    "'''\n",
    "Create the object of the GradientBoosting Classifier model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : learning_rate, n_estimators\n",
    "Documentation of sklearn GradientBoosting Classifier: \n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html\n",
    "'''\n",
    "model = GradientBoostingClassifier(n_estimators=100,max_depth=5)\n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('\\nTarget on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('\\nTarget on test data',predict_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(test_y,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d711972",
   "metadata": {},
   "source": [
    "# XG BOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c18283b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9676/888958075.py, line 58)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/888958075.py\"\u001b[1;36m, line \u001b[1;32m58\u001b[0m\n\u001b[1;33m    print('\\naccuracy_score on test dataset : ', accuracy_test)''\u001b[0m\n\u001b[1;37m                                                               ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "The following code is for XGBoost\n",
    "Created by - ANALYTICS VIDHYA\n",
    "'''\n",
    "\n",
    "# importing required libraries\n",
    "import pandas as pd\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# read the train and test dataset\n",
    "train_data = pd.read_csv('train-data.csv')\n",
    "test_data = pd.read_csv('test-data.csv')\n",
    "\n",
    "# shape of the dataset\n",
    "print('Shape of training data :',train_data.shape)\n",
    "print('Shape of testing data :',test_data.shape)\n",
    "\n",
    "# Now, we need to predict the missing target variable in the test data\n",
    "# target variable - Survived\n",
    "\n",
    "# seperate the independent and target variable on training data\n",
    "train_x = train_data.drop(columns=['Survived'],axis=1)\n",
    "train_y = train_data['Survived']\n",
    "\n",
    "# seperate the independent and target variable on testing data\n",
    "test_x = test_data.drop(columns=['Survived'],axis=1)\n",
    "test_y = test_data['Survived']\n",
    "\n",
    "'''\n",
    "Create the object of the XGBoost model\n",
    "You can also add other parameters and test your code here\n",
    "Some parameters are : max_depth and n_estimators\n",
    "Documentation of xgboost:\n",
    "\n",
    "https://xgboost.readthedocs.io/en/latest/\n",
    "'''\n",
    "model = XGBClassifier()\n",
    "\n",
    "# fit the model with the training data\n",
    "model.fit(train_x,train_y)\n",
    "\n",
    "\n",
    "# predict the target on the train dataset\n",
    "predict_train = model.predict(train_x)\n",
    "print('\\nTarget on train data',predict_train) \n",
    "\n",
    "# Accuray Score on train dataset\n",
    "accuracy_train = accuracy_score(train_y,predict_train)\n",
    "print('\\naccuracy_score on train dataset : ', accuracy_train)\n",
    "\n",
    "# predict the target on the test dataset\n",
    "predict_test = model.predict(test_x)\n",
    "print('\\nTarget on test data',predict_test) \n",
    "\n",
    "# Accuracy Score on test dataset\n",
    "accuracy_test = accuracy_score(test_y,predict_test)\n",
    "print('\\naccuracy_score on test dataset : ', accuracy_test)''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396835ac",
   "metadata": {},
   "source": [
    "# Feature selction by Chi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ee5eb92",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9676/804409797.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/804409797.py\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    ''X, y = load_iris(return_X_y=True)\u001b[0m\n\u001b[1;37m      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "\n",
    " ''X, y = load_iris(return_X_y=True)\n",
    "    X_new = SelectKBest(chi2, k=4).fit_transform(X, y)''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5302b471",
   "metadata": {},
   "source": [
    "# Tree based fetaure selcting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3790997b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (Temp/ipykernel_9676/2823973299.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\GOPINA~1\\AppData\\Local\\Temp/ipykernel_9676/2823973299.py\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    array([ 0.04...,  0.05...,  0.4...,  0.4...])\u001b[0m\n\u001b[1;37m                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    ">>> from sklearn.ensemble import ExtraTreesClassifier\n",
    ">>> from sklearn.datasets import load_iris\n",
    ">>> from sklearn.feature_selection import SelectFromModel\n",
    ">>> X, y = load_iris(return_X_y=True)\n",
    ">>> X.shape\n",
    "(150, 4)\n",
    ">>> clf = ExtraTreesClassifier(n_estimators=50)\n",
    ">>> clf = clf.fit(X, y)\n",
    ">>> clf.feature_importances_  \n",
    "array([ 0.04...,  0.05...,  0.4...,  0.4...])\n",
    ">>> model = SelectFromModel(clf, prefit=True)\n",
    ">>> X_new = model.transform(X)\n",
    ">>> X_new.shape               \n",
    "(150, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39a68651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X, y = make_classification(\n",
    "    n_samples=1000,\n",
    "    n_features=10,\n",
    "    n_informative=3,\n",
    "    n_redundant=0,\n",
    "    n_repeated=0,\n",
    "    n_classes=2,\n",
    "    random_state=0,\n",
    "    shuffle=False,\n",
    ")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aabf0ea",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
